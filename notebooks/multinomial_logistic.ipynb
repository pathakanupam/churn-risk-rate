{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task : Predict the churn score for a website based on the features provided in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'F:\\Projects\\Hackathons\\HE\\churn_risk_rate\\dataset\\train.csv')\n",
    "test = pd.read_csv(r'F:\\Projects\\Hackathons\\HE\\churn_risk_rate\\dataset\\test.csv')\n",
    "# Dropping unimportant columns\n",
    "\n",
    "output = pd.DataFrame(columns = ['customer_id','churn_risk_score'])\n",
    "output['customer_id'] = test['customer_id']\n",
    "cols_to_drop = ['customer_id', 'Name', 'security_no']\n",
    "train = train.drop(cols_to_drop, axis = 1)\n",
    "test = test.drop(cols_to_drop, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer_gender = SimpleImputer(missing_values = 'Unknown', strategy='most_frequent')\n",
    "train.loc[:,'gender'] = imputer_gender.fit_transform(train.loc[:,'gender'].to_numpy().reshape(-1,1))\n",
    "\n",
    "test.loc[:,'gender'] = imputer_gender.transform(test.loc[:,'gender'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer_medium_of_operation = SimpleImputer(missing_values = '?', strategy='most_frequent')\n",
    "train.loc[:,'medium_of_operation'] = imputer_medium_of_operation.fit_transform(train.loc[:,'medium_of_operation'].to_numpy().reshape(-1,1))\n",
    "test.loc[:,'medium_of_operation'] = imputer_medium_of_operation.transform(test.loc[:,'medium_of_operation'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train. avg_frequency_login_days = train.avg_frequency_login_days.replace({'Error':np.nan})\n",
    "train.avg_frequency_login_days = pd.to_numeric(train.avg_frequency_login_days)\n",
    "\n",
    "test.avg_frequency_login_days = test.avg_frequency_login_days.replace({'Error':np.nan})\n",
    "test.avg_frequency_login_days = pd.to_numeric(test.avg_frequency_login_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer_avg_f_login_days = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "train.loc[:,'avg_frequency_login_days'] = imputer_avg_f_login_days.fit_transform(train.loc[:,'avg_frequency_login_days'].to_numpy().reshape(-1,1))\n",
    "\n",
    "test.loc[:,'avg_frequency_login_days'] = imputer_avg_f_login_days.transform(test.loc[:,'avg_frequency_login_days'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train.shape[0]): \n",
    "    if train.loc[i, 'joined_through_referral'] == '?' : \n",
    "        if train.loc[i, 'referral_id'] == 'xxxxxxxx' : \n",
    "            train.loc[i, 'joined_through_referral'] = 'No'\n",
    "        else : \n",
    "            train.loc[i, 'joined_through_referral'] = 'Yes'\n",
    "\n",
    "for i in range(test.shape[0]):           \n",
    "    if test.loc[i, 'joined_through_referral'] == '?' : \n",
    "        if test.loc[i, 'referral_id'] == 'xxxxxxxx' : \n",
    "            test.loc[i, 'joined_through_referral'] = 'No'\n",
    "        else : \n",
    "            test.loc[i, 'joined_through_referral'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols  = ['region_category', 'preferred_offer_types']\n",
    "\n",
    "imputer_cat = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "train.loc[:,cols] = imputer_cat.fit_transform(train.loc[:,cols])\n",
    "test.loc[:,cols] = imputer_cat.fit_transform(test.loc[:,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_points_in_wallet = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "\n",
    "train.loc[:,'points_in_wallet'] = imputer_points_in_wallet.fit_transform(train.loc[:,'points_in_wallet'].to_numpy().reshape(-1,1))\n",
    "test.loc[:,'points_in_wallet'] = imputer_points_in_wallet.fit_transform(test.loc[:,'points_in_wallet'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['referral_id', 'joining_date', 'last_visit_time'], axis = 1)\n",
    "test = test.drop(['referral_id', 'joining_date', 'last_visit_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.avg_time_spent = abs(train.avg_time_spent)\n",
    "test.avg_time_spent = abs(test.avg_time_spent)\n",
    "\n",
    "train.avg_frequency_login_days = abs(train.avg_frequency_login_days)\n",
    "test.avg_frequency_login_days = abs(test.avg_frequency_login_days)\n",
    "\n",
    "for i in range(train.shape[0]) :\n",
    "    if train.loc[i,'days_since_last_login'] < 0 : \n",
    "        train.loc[i,'days_since_last_login'] = 0\n",
    "\n",
    "for i in range(test.shape[0]) : \n",
    "    if test.loc[i,'days_since_last_login'] < 0 : \n",
    "        test.loc[i,'days_since_last_login'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2_onehotencode = ['gender', 'region_category', 'membership_category',\n",
    "       'joined_through_referral', 'preferred_offer_types',\n",
    "       'medium_of_operation', 'internet_option', 'used_special_discount',\n",
    "       'offer_application_preference', 'past_complaint', 'complaint_status',\n",
    "       'feedback']\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),cols_2_onehotencode)], remainder='passthrough')\n",
    "X_train = ct.fit_transform(X_train)\n",
    "X_test = ct.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver = 'saga', max_iter = 4000).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross_val_score(model,X_train, y_train,cv = 10, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['churn_risk_score'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('F:\\Projects\\Hackathons\\HE\\churn_risk_rate\\outputs\\out1.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  116,   41,  359,  181,  466],\n",
       "       [   0, 2362,  290,    0,    0,    0],\n",
       "       [   0, 1682, 1059,    0,    0,    0],\n",
       "       [   0,    0,    0, 9148, 1276,    0],\n",
       "       [   0,    0,    0, 1281, 3997, 4907],\n",
       "       [   0,    0,    0,    0,  235, 9592]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
